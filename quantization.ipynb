{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TePhfFhO63fn",
        "outputId": "82e8d69a-67a6-4c5e-aeb0-3cdbaa1b2386"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'pytorch-cifar100'...\n",
            "remote: Enumerating objects: 1037, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 1037 (delta 0), reused 1 (delta 0), pack-reused 1033\u001b[K\n",
            "Receiving objects: 100% (1037/1037), 498.95 KiB | 5.20 MiB/s, done.\n",
            "Resolving deltas: 100% (649/649), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/nxquang-al/pytorch-cifar100.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeXHVHUO7ioq",
        "outputId": "067e377a-8104-480c-fe3e-924eeae335e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/pytorch-cifar100\n"
          ]
        }
      ],
      "source": [
        "%cd pytorch-cifar100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eirF2GVZ6mCt"
      },
      "outputs": [],
      "source": [
        "!mkdir checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Train the baseline model\n",
        "# !python train.py -net resnet34 -gpu"
      ],
      "metadata": {
        "id": "-kPziqvHHK6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5bC2s2m7sMM"
      },
      "source": [
        "# Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XN6Ez59w6eEp"
      },
      "outputs": [],
      "source": [
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "t7ggdtor6hkn",
        "outputId": "1fdef520-0683-4423-ab70-0d911e1c97ba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1b3Xls00FQXokbYnhKEFm7A2QWFg04_Q1\n",
            "To: /content/pytorch-cifar100/checkpoints/resnet34-baseline.pth\n",
            "100%|██████████| 85.5M/85.5M [00:05<00:00, 16.8MB/s]\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./checkpoints/resnet34-baseline.pth'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gdown\n",
        "\n",
        "id = \"1b3Xls00FQXokbYnhKEFm7A2QWFg04_Q1\"\n",
        "output = \"./checkpoints/resnet34-baseline.pth\"\n",
        "gdown.download(id=id, output=output, quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbYaeuSf66gC"
      },
      "outputs": [],
      "source": [
        "# # Download torchscript static-quantized int8 model\n",
        "\n",
        "# static_jit_id = \"1UGl3aJRzqMaN-IcUpCoOtpKHSV7HE-KN\"\n",
        "# output = \"./checkpoints/resnet34-static-int8-jit.pt\"\n",
        "# gdown.download(id=static_jit_id, output=output, quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83iEuei67k3w"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/pytorch-cifar100/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKCUaq767niP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import copy\n",
        "import os\n",
        "import copy\n",
        "import time\n",
        "from models.resnet import resnet34"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yV9U0SrHx706",
        "outputId": "8b50ac43-091b-4db0-ab0c-5e95a17ea536"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.is_available())\n",
        "\n",
        "cuda_device = torch.device(\"cuda:0\")\n",
        "cpu_device = torch.device(\"cpu:0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJY7f2h-8oOh",
        "outputId": "9b33db67-1946-4c8d-e9aa-76b38d46ffdf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (conv2_x): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (add_relu): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (add_relu): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (add_relu): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (conv3_x): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (add_relu): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (add_relu): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (add_relu): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (3): BasicBlock(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (add_relu): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (conv4_x): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (add_relu): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (add_relu): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (add_relu): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (3): BasicBlock(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (add_relu): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (4): BasicBlock(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (add_relu): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (5): BasicBlock(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (add_relu): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (conv5_x): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (add_relu): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (add_relu): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (add_relu): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=100, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "baseline = resnet34()\n",
        "baseline.load_state_dict(torch.load(\"./checkpoints/resnet34-baseline.pth\"))\n",
        "baseline.to(cuda_device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAVa_pjZ7RLB"
      },
      "outputs": [],
      "source": [
        "static_int8_jit = torch.jit.load(\n",
        "    \"./checkpoints/resnet34-static-int8-jit.pt\",\n",
        "    map_location=cpu_device\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-zFJ_99C3q-"
      },
      "outputs": [],
      "source": [
        "assert next(baseline.parameters()).device == cuda_device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ladPhHrqDguZ"
      },
      "source": [
        "# CIFAR-100 Dataloader Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQVrUg1mDQjn",
        "outputId": "f176e5d1-4a63-4e72-f098-2a4d6823cdb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 169001437/169001437 [00:05<00:00, 29095386.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "from utils import get_test_dataloader\n",
        "from conf import settings\n",
        "\n",
        "test_loader = get_test_dataloader(\n",
        "        settings.CIFAR100_TRAIN_MEAN,\n",
        "        settings.CIFAR100_TRAIN_STD,\n",
        "        num_workers=4,\n",
        "        batch_size=1,\n",
        "        shuffle=True\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoSvEIocDpT7"
      },
      "source": [
        "# Metrics Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmIjKhMGDnku"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, test_loader, device=cuda_device):\n",
        "    \"\"\"Evaluate model accuracy, top-1 error rate, and top-5 error rate\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0.0\n",
        "    correct_1 = 0.0\n",
        "    correct_5 = 0.0\n",
        "\n",
        "    for (images, labels) in test_loader:\n",
        "\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "\n",
        "        top5_preds = torch.topk(outputs,5,1,largest=True,sorted=True)[1]\n",
        "        labs = labels.view(labels.size(0),-1).expand_as(top5_preds)\n",
        "        corrects = torch.eq(top5_preds, labs).float()\n",
        "        correct_5 += torch.sum(corrects[:,:5])\n",
        "        correct_1 += torch.sum(corrects[:,:1])\n",
        "\n",
        "    acc = correct_1.float() / len(test_loader.dataset)\n",
        "    top_1_error = 1 - correct_1.float() / len(test_loader.dataset)\n",
        "    top_5_error = 1 - correct_5.float() / len(test_loader.dataset)\n",
        "    print('Evaluating Network.....')\n",
        "    print('Test set: Accuracy: {:.4f}, Top-1 Error: {:.4f}, Top-5 Error: {:.4f}'.format(\n",
        "        acc, top_1_error, top_5_error\n",
        "    ))\n",
        "\n",
        "    return acc, top_1_error, top_5_error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_KLnQMyFO-D"
      },
      "source": [
        "# UTILS: Memory and Inference Time Measurements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQ0VmfYDFXQG"
      },
      "source": [
        "## 1. Memory Usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGK-VSUrFccj"
      },
      "outputs": [],
      "source": [
        "from torch.profiler import profile, record_function, ProfilerActivity\n",
        "\n",
        "def cpu_memory_measure(model):\n",
        "  model = copy.deepcopy(model).to(cpu_device)\n",
        "  inputs = torch.randn(1, 3, 32, 32, dtype=torch.float).to(cpu_device)\n",
        "\n",
        "  with profile(activities=[ProfilerActivity.CPU],\n",
        "          profile_memory=True, record_shapes=True) as prof:\n",
        "      model(inputs)\n",
        "\n",
        "  print(prof.key_averages().table(sort_by=\"cpu_memory_usage\", row_limit=10))\n",
        "\n",
        "def cuda_memory_measure(model):\n",
        "  model = copy.deepcopy(model).to(cuda_device)\n",
        "  inputs = torch.randn(1, 3, 224, 224, dtype=torch.float).to(cuda_device)\n",
        "\n",
        "  with profile(activities=[ProfilerActivity.CUDA],\n",
        "          profile_memory=True, record_shapes=True) as prof:\n",
        "      model(inputs)\n",
        "\n",
        "  print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BWH6Q9ZFgSR"
      },
      "source": [
        "## 2. Inference Time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6ax2wy0FfdZ"
      },
      "outputs": [],
      "source": [
        "# GPU Inference Time (parallel)\n",
        "import numpy as np\n",
        "\n",
        "def gpu_time_measure(model, warmup=10):\n",
        "  model = copy.deepcopy(model).to(cuda_device)\n",
        "  dummy_input = torch.randn(1, 3, 32, 32, dtype=torch.float).to(cuda_device)\n",
        "\n",
        "  # INIT LOGGERS\n",
        "  starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(\n",
        "      enable_timing=True\n",
        "  )\n",
        "  repetitions = 300\n",
        "  timings = np.zeros((repetitions, 1))\n",
        "  # GPU-WARM-UP\n",
        "  for _ in range(warmup):\n",
        "      _ = model(dummy_input)\n",
        "  torch.cuda.synchronize()\n",
        "\n",
        "  # MEASURE PERFORMANCE\n",
        "  with torch.no_grad():\n",
        "      for rep in range(repetitions):\n",
        "          starter.record()\n",
        "          _ = model(dummy_input)\n",
        "          ender.record()\n",
        "          # WAIT FOR GPU SYNC\n",
        "          torch.cuda.synchronize()\n",
        "          curr_time = starter.elapsed_time(ender)\n",
        "          timings[rep] = curr_time\n",
        "\n",
        "  mean_syn = np.sum(timings) / repetitions\n",
        "  std_syn = np.std(timings)\n",
        "  return mean_syn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTo3_-0SihV0"
      },
      "outputs": [],
      "source": [
        "def cpu_time_measure_cifar(model, test_loader, device=cpu_device, warmup=10):\n",
        "    model = model.to(cpu_device)\n",
        "    model.eval()\n",
        "\n",
        "    # warmup for sure\n",
        "    dummy_input = torch.randn(1, 3, 32, 32, dtype=torch.float).to(cpu_device)\n",
        "    for _ in range(warmup):\n",
        "      _ = model(dummy_input)\n",
        "    torch.cuda.synchronize()\n",
        "    elapsed_time = 0\n",
        "\n",
        "    for batch_index, (images, labels) in enumerate(test_loader):\n",
        "        if batch_index >= 100:\n",
        "            break\n",
        "\n",
        "        images = images.to(device)\n",
        "        print(images[0].shape)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        start = time.time()\n",
        "        outputs = model(images)\n",
        "        stop = time.time()\n",
        "        elapsed_time += (stop - start)\n",
        "\n",
        "\n",
        "    mean_syn = elapsed_time / batch_index\n",
        "\n",
        "    return mean_syn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6ht6Qj1Dk6l"
      },
      "source": [
        "# UTILS: Save model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(model, save_dir, filename):\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "    save_path = os.path.join(save_dir, filename)\n",
        "    torch.save(model.state_dict(), save_path)"
      ],
      "metadata": {
        "id": "sHACt49OEk9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GB2iTckWDmin"
      },
      "outputs": [],
      "source": [
        "# TorchScript Serialization\n",
        "\n",
        "def save_jit_model(model, save_dir, filename):\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "    save_path = os.path.join(save_dir, filename)\n",
        "    torch.jit.save(torch.jit.script(model), save_path)\n",
        "\n",
        "def load_jit_model(model_path, device):\n",
        "    return torch.jit.load(model_path, map_location=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2fumN3jDI-x"
      },
      "outputs": [],
      "source": [
        "def get_model_size(model):\n",
        "    model_dir = os.path.join(\"/tmp\", \"temp\")\n",
        "    torch.save(model.state_dict(), model_dir)\n",
        "    # model.save_pretrained(model_dir)\n",
        "    size = os.path.getsize(model_dir)\n",
        "    os.remove(model_dir)\n",
        "\n",
        "    return size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jFDrt7xEdBd"
      },
      "source": [
        "# QUANTIZATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnQbcj5NEpOR"
      },
      "source": [
        "## 1. Dynamic Quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9FDYAQwEwY0"
      },
      "outputs": [],
      "source": [
        "baseline_cpu = copy.deepcopy(baseline).to(cpu_device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxWSheU9E-eZ"
      },
      "outputs": [],
      "source": [
        "# Quantize to float16\n",
        "dynamic_fp16_model = torch.quantization.quantize_dynamic(\n",
        "    baseline_cpu,\n",
        "    {torch.nn.Linear, torch.nn.Conv2d},\n",
        "    dtype=torch.float16\n",
        ")\n",
        "\n",
        "# evaluate float16 model\n",
        "evaluate(dynamic_fp16_model, test_loader, cpu_device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIWhxXuVEz96"
      },
      "outputs": [],
      "source": [
        "# Quantize the model to int8\n",
        "dynamic_int8_model = torch.quantization.quantize_dynamic(\n",
        "    baseline_cpu,\n",
        "     {torch.nn.Linear, torch.nn.Conv2d},\n",
        "    dtype=torch.qint8\n",
        ")\n",
        "\n",
        "# evaluate int8 model\n",
        "evaluate(dynamic_int8_model, test_loader, cpu_device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxwLFdLsDMpV"
      },
      "source": [
        "## 2. Post-training Static Quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUWBnmktDPa0"
      },
      "outputs": [],
      "source": [
        "class QuantizedResNet34(nn.Module):\n",
        "    def __init__(self, model_fp32):\n",
        "        super(QuantizedResNet34, self).__init__()\n",
        "        self.quant = QuantStub()\n",
        "        self.dequant = DeQuantStub()\n",
        "        self.model = model_fp32\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.quant(x)\n",
        "        x = self.model(x)\n",
        "        x = self.dequant(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZ5VV6fFDaNA"
      },
      "outputs": [],
      "source": [
        "from torch.ao.quantization import QuantStub, DeQuantStub\n",
        "import torch.nn as nn\n",
        "\n",
        "def calibrate_model(model, dataloader, device=\"cpu:0\"):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    for images, labels in dataloader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "\n",
        "def quantize_static(model):\n",
        "    device = torch.device(\"cpu:0\")\n",
        "    model = model.to(device)\n",
        "    fused_model = copy.deepcopy(model)\n",
        "    model.eval()\n",
        "    fused_model.eval()\n",
        "\n",
        "    for module_name, module in fused_model.named_children():\n",
        "        if \"conv1\" in module_name:\n",
        "            torch.ao.quantization.fuse_modules(module,[[\"0\", \"1\", \"2\"]], inplace=True)\n",
        "        elif \"conv\" in module_name:\n",
        "            for basic_block_name, basic_block in module.named_children():\n",
        "                for sub_block_name, sub_block in basic_block.named_children():\n",
        "                    if sub_block_name == \"residual_function\":\n",
        "                        torch.ao.quantization.fuse_modules(sub_block, [[\"0\", \"1\", \"2\"], [\"3\", \"4\"]], inplace=True)\n",
        "                    elif sub_block_name == \"shortcut\" and len(sub_block):\n",
        "                        torch.ao.quantization.fuse_modules(sub_block, [[\"0\", \"1\"]], inplace=True)\n",
        "    print(\"After fusion: \", fused_model)\n",
        "\n",
        "    quantized_model = QuantizedResNet34(fused_model)\n",
        "    quantized_model.qconfig = torch.quantization.get_default_qconfig(\"fbgemm\")\n",
        "    print(quantized_model.qconfig)\n",
        "\n",
        "    torch.ao.quantization.prepare(quantized_model, inplace=True)\n",
        "    calibrate_model(\n",
        "        model=quantized_model, dataloader=train_loader, device=torch.device(\"cpu:0\")\n",
        "    )\n",
        "    quantized_model = torch.ao.quantization.convert(quantized_model, inplace=True)\n",
        "\n",
        "    return quantized_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0a4hAPnXDh04"
      },
      "outputs": [],
      "source": [
        "static_int8_model = quantize_static(baseline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKGTpG0kDj3e"
      },
      "outputs": [],
      "source": [
        "static_int8_model.eval()\n",
        "evaluate(static_int8_model, test_loader, \"cpu:0\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFi3ofW_DlEa"
      },
      "source": [
        "## 3. Quantize-aware Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "la1U83m-Dov0"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, test_loader, device, learning_rate=0.1, num_epochs=100):\n",
        "    \"\"\"A simple trainer\"\"\"\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)\n",
        "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=settings.MILESTONES, gamma=0.2)\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0\n",
        "        running_corrects = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = loss_function(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # statistics\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        train_loss = running_loss / len(train_loader.dataset)\n",
        "        train_acc = running_corrects / len(train_loader.dataset)\n",
        "\n",
        "        # Evaluation\n",
        "        model.eval()\n",
        "        val_acc, top1_error, top5_error = evaluate(model=model, test_loader=test_loader, device=device)\n",
        "\n",
        "        # Set learning rate scheduler\n",
        "        scheduler.step()\n",
        "\n",
        "        print(\"Epoch: {:03d} Train Loss: {:.3f} Train Acc: {:.3f} Val Acc: {:.3f} Top-5 Error: {:.3f}\".format(\n",
        "            epoch,\n",
        "            train_loss,\n",
        "            train_acc,\n",
        "            val_acc,\n",
        "            top5_error)\n",
        "        )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCAUtEvDDrzc"
      },
      "outputs": [],
      "source": [
        "def quantized_aware_training(model, train_loader, test_loader):\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    model = model.to(device)\n",
        "    fused_model = copy.deepcopy(model)\n",
        "    model.eval()\n",
        "    fused_model.eval()\n",
        "\n",
        "    # fuse the model inplace\n",
        "    for module_name, module in fused_model.named_children():\n",
        "        if \"conv1\" in module_name:\n",
        "            torch.ao.quantization.fuse_modules(module,[[\"0\", \"1\", \"2\"]], inplace=True)\n",
        "        elif \"conv\" in module_name:\n",
        "            for basic_block_name, basic_block in module.named_children():\n",
        "                for sub_block_name, sub_block in basic_block.named_children():\n",
        "                    if sub_block_name == \"residual_function\":\n",
        "                        torch.ao.quantization.fuse_modules(sub_block, [[\"0\", \"1\", \"2\"], [\"3\", \"4\"]], inplace=True)\n",
        "                    elif sub_block_name == \"shortcut\" and len(sub_block):\n",
        "                        torch.ao.quantization.fuse_modules(sub_block, [[\"0\", \"1\"]], inplace=True)\n",
        "\n",
        "    quantized_model = QuantizedResNet34(fused_model)\n",
        "    quantized_model.qconfig = torch.quantization.get_default_qconfig(\"fbgemm\")\n",
        "\n",
        "    # prepare for quatized aware-training\n",
        "    torch.quantization.prepare_qat(quantized_model, inplace=True)\n",
        "\n",
        "    quantized_model.train()\n",
        "    train_model(quantized_model, train_loader, test_loader, device=torch.device(\"cuda:0\"), learning_rate=0.1, num_epochs=10)\n",
        "\n",
        "    quantized_model.to(torch.device(\"cpu:0\"))\n",
        "    quantized_model = torch.quantization.convert(quantized_model, inplace=True)\n",
        "\n",
        "    return quantized_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfvL7yS-D2xG"
      },
      "outputs": [],
      "source": [
        "qat_model = quantized_aware_training(baseline, train_loader, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3o_2WqOD6pW"
      },
      "outputs": [],
      "source": [
        "qat_model.eval()\n",
        "evaluate(qat_model, test_loader, \"cpu:0\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fzj2jT1frS7I"
      },
      "source": [
        "# MEASUREMENTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jX6MkbVN-1Jg"
      },
      "source": [
        "## 1. Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22OgTaYJEVoa"
      },
      "outputs": [],
      "source": [
        "# Accuracy, Top-1 error rate, Top-5 error rate\n",
        "evaluate(baseline, test_loader, device=cuda_device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvO8UCjO_Fvu",
        "outputId": "1b4ed1d0-dd2d-44c0-8425-7a954a006622"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                            Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
            "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                     aten::empty         1.18%     613.000us         1.18%     613.000us       2.128us      14.19 Mb      14.19 Mb           288  \n",
            "                    aten::conv2d         0.62%     321.000us        85.80%      44.407ms       1.234ms       3.91 Mb           0 b            36  \n",
            "               aten::convolution         1.01%     525.000us        85.18%      44.086ms       1.225ms       3.91 Mb           0 b            36  \n",
            "              aten::_convolution         2.09%       1.080ms        84.16%      43.561ms       1.210ms       3.91 Mb           0 b            36  \n",
            "                aten::batch_norm         0.26%     132.000us        10.48%       5.422ms     150.611us       3.91 Mb           0 b            36  \n",
            "    aten::_batch_norm_impl_index         5.49%       2.840ms        10.22%       5.290ms     146.944us       3.91 Mb           0 b            36  \n",
            "         aten::native_batch_norm         3.81%       1.972ms         4.59%       2.378ms      66.056us       3.91 Mb     -59.25 Kb            36  \n",
            "                aten::empty_like         0.21%     109.000us         0.44%     230.000us       6.389us       3.91 Mb     384.00 Kb            36  \n",
            "        aten::mkldnn_convolution        30.49%      15.783ms        30.88%      15.981ms     940.059us       2.75 Mb           0 b            17  \n",
            "                       aten::add         1.17%     608.000us         1.17%     608.000us      38.000us       1.72 Mb       1.72 Mb            16  \n",
            "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 51.758ms\n",
            "\n"
          ]
        }
      ],
      "source": [
        "cpu_memory_measure(baseline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjqajRXKkIos",
        "outputId": "b48a061e-526e-43e1-df4d-c2eb26ddf8cb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline inference time using GPU: 53.5507 ms/sample\n"
          ]
        }
      ],
      "source": [
        "print(\"Baseline inference time using CPU: {:.4f} ms/sample\".format(cpu_time_measure_cifar(baseline, test_loader) * 1000))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFxNxdIs-3Sg"
      },
      "source": [
        "## 2. Dynamic Quantized Float16"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(dynamic_fp16_model, test_loader, device=cpu_device)"
      ],
      "metadata": {
        "id": "IlRgtAOSF1Vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAowmC6N_b9d",
        "outputId": "fcbaa3da-e2b3-4d90-a20c-fdc6b05a374e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                              Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
            "----------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                       aten::empty         1.12%     488.000us         1.12%     488.000us       1.689us      14.18 Mb      14.18 Mb           289  \n",
            "                      aten::conv2d         0.43%     186.000us        90.32%      39.288ms       1.091ms       3.91 Mb           0 b            36  \n",
            "                 aten::convolution         1.26%     546.000us        89.90%      39.102ms       1.086ms       3.91 Mb           0 b            36  \n",
            "                aten::_convolution         0.97%     423.000us        88.64%      38.556ms       1.071ms       3.91 Mb           0 b            36  \n",
            "                  aten::batch_norm         0.35%     154.000us         5.67%       2.468ms      68.556us       3.91 Mb      32.00 Kb            36  \n",
            "      aten::_batch_norm_impl_index         0.62%     271.000us         5.41%       2.355ms      65.417us       3.91 Mb           0 b            36  \n",
            "           aten::native_batch_norm         3.96%       1.721ms         4.63%       2.015ms      55.972us       3.91 Mb     -64.00 Kb            36  \n",
            "                  aten::empty_like         0.23%     101.000us         0.41%     178.000us       4.944us       3.91 Mb     256.00 Kb            36  \n",
            "          aten::mkldnn_convolution        36.10%      15.701ms        36.57%      15.907ms     935.706us       2.75 Mb           0 b            17  \n",
            "                         aten::add         1.39%     605.000us         1.39%     605.000us      37.812us       1.72 Mb       1.72 Mb            16  \n",
            "----------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 43.497ms\n",
            "\n"
          ]
        }
      ],
      "source": [
        "cpu_memory_measure(dynamic_fp16_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qN5uzos4lMZ1",
        "outputId": "224f6f25-3b70-49c0-e425-bd1de4c2583b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dynamic Float16 inference time using GPU: 47.1648 ms/sample\n"
          ]
        }
      ],
      "source": [
        "print(\"Dynamic Float16 inference time using GPU: {:.4f} ms/sample\".format(cpu_time_measure_cifar(dynamic_fp16_model, test_loader) * 1000))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lphjQjpw-9G8"
      },
      "source": [
        "## 3. Dynamic Quantized Int8"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(dynamic_int8_model, test_loader, device=cpu_device)"
      ],
      "metadata": {
        "id": "zI_Dh8tyGHgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaFJ547C_sSQ",
        "outputId": "ea33c793-bbe9-468e-a3eb-e3313d61b738"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                            Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
            "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                     aten::empty         1.37%     681.000us         1.37%     681.000us       2.348us      14.07 Mb      14.07 Mb           290  \n",
            "                aten::empty_like         0.26%     129.000us         0.47%     233.000us       6.297us       3.91 Mb     512.00 Kb            37  \n",
            "                    aten::conv2d         2.43%       1.209ms        86.07%      42.804ms       1.189ms       3.91 Mb     128.00 Kb            36  \n",
            "               aten::convolution         1.15%     573.000us        85.60%      42.569ms       1.182ms       3.91 Mb           0 b            36  \n",
            "              aten::_convolution         0.84%     419.000us        84.44%      41.996ms       1.167ms       3.91 Mb           0 b            36  \n",
            "                aten::batch_norm         0.26%     131.000us         5.89%       2.929ms      81.361us       3.91 Mb           0 b            36  \n",
            "    aten::_batch_norm_impl_index         0.59%     295.000us         5.63%       2.798ms      77.722us       3.91 Mb           0 b            36  \n",
            "         aten::native_batch_norm         4.12%       2.049ms         4.85%       2.410ms      66.944us       3.91 Mb     -61.75 Kb            36  \n",
            "        aten::mkldnn_convolution        33.15%      16.484ms        33.64%      16.730ms     984.118us       2.75 Mb           0 b            17  \n",
            "                       aten::add         1.78%     883.000us         1.78%     883.000us      55.188us       1.72 Mb       1.72 Mb            16  \n",
            "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 49.732ms\n",
            "\n"
          ]
        }
      ],
      "source": [
        "cpu_memory_measure(dynamic_int8_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4dUmmKSlPsV",
        "outputId": "6e2a462e-7ca6-433b-f976-36bc9891ee5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dynamic Int8 inference time using GPU: 49.1005 ms/sample\n"
          ]
        }
      ],
      "source": [
        "print(\"Dynamic Int8 inference time using GPU: {:.4f} ms/sample\".format(cpu_time_measure_cifar(dynamic_int8_model, test_loader) * 1000))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEUD86pH_Axs"
      },
      "source": [
        "## 4. Static Quantized Int8"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(static_int8_jit, test_loader, cpu_device)"
      ],
      "metadata": {
        "id": "lLol92bJGLEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRNbz1gZ_3F9",
        "outputId": "8babe0a4-de58-4762-bf02-47c75b516a9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                      aten::empty         0.34%      67.000us         0.34%      67.000us       1.763us       3.84 Mb       3.84 Mb            38  \n",
            "    aten::_empty_affine_quantized         0.72%     144.000us         0.72%     144.000us       2.618us       1.41 Mb       1.41 Mb            55  \n",
            "           quantized::conv2d_relu        45.32%       9.006ms        45.97%       9.137ms     537.471us     501.00 Kb      -1.97 Mb            17  \n",
            "                quantized::conv2d        47.74%       9.488ms        48.16%       9.571ms     503.737us      24.00 Kb      -2.34 Mb            19  \n",
            "        aten::quantize_per_tensor         0.13%      26.000us         0.13%      26.000us      26.000us       3.00 Kb       3.00 Kb             1  \n",
            "                 aten::contiguous         0.03%       5.000us         0.23%      45.000us      45.000us       3.00 Kb           0 b             1  \n",
            "                      aten::clone         0.17%      34.000us         0.20%      40.000us      40.000us       3.00 Kb           0 b             1  \n",
            "        aten::adaptive_avg_pool2d         0.08%      16.000us         0.28%      56.000us      56.000us         512 b           0 b             1  \n",
            "       aten::_adaptive_avg_pool2d         0.19%      38.000us         0.20%      40.000us      40.000us         512 b           0 b             1  \n",
            "                          forward         1.91%     380.000us       100.00%      19.874ms      19.874ms         400 b    -112.50 Kb             1  \n",
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 19.874ms\n",
            "\n"
          ]
        }
      ],
      "source": [
        "cpu_memory_measure(static_int8_jit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vHiYJY1kjwv",
        "outputId": "ef9c3ab6-cf01-4243-bdef-9cd8cef20c32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Static Int8 JIT inference time using GPU: 20.5449 ms/sample\n"
          ]
        }
      ],
      "source": [
        "print(\"Static Int8 JIT inference time using GPU: {:.4f} ms/sample\".format(cpu_time_measure_cifar(static_int8_jit, test_loader) * 1000))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SAVE MODELS"
      ],
      "metadata": {
        "id": "78I8QvMPFEa2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save as a PyTorch model\n",
        "save_model(model=baseline, save_dir=\"./checkpoints\", filename=\"resnet34-baseline.pth\")\n",
        "# Save as TorchScript model\n",
        "save_jit_model(model=baseline, save_dir=\"./checkpoints\", filename=\"resnet34-baseline-jit.pth\")"
      ],
      "metadata": {
        "id": "AThzNLPIFHde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save dynamic quantize float16 model\n",
        "save_model(model=dynamic_fp16_model, save_dir=\"./checkpoints\", filename=\"resnet34-dynamic-float16.pth\")"
      ],
      "metadata": {
        "id": "_c1jgup7FdaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save dynamic quantize int8 model\n",
        "save_model(model=dynamic_int8_model, save_dir=\"./checkpoints\", filename=\"resnet34-dynamic-int8.pth\")"
      ],
      "metadata": {
        "id": "cOObzu3fFmmY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ladPhHrqDguZ",
        "6_KLnQMyFO-D",
        "X6ht6Qj1Dk6l",
        "3jFDrt7xEdBd",
        "YFi3ofW_DlEa",
        "Fzj2jT1frS7I",
        "78I8QvMPFEa2"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}